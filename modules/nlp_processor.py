"""
M√≥dulo principal de processamento NLP para documentos jur√≠dicos
Integra todos os componentes: NER, Sumariza√ß√£o e prepara√ß√£o para RAG
Implementa a metodologia "Estrategista Jur√≠dico-Cognitivo"
"""

from typing import Dict, Any, List, Optional
import warnings
warnings.filterwarnings('ignore')

from .legal_ner import LegalEntityExtractor, extract_legal_entities
from .legal_summarizer import LegalSummarizer, summarize_legal_text
from .rag_indexer import RAGIndexer


class LegalNLPProcessor:
    """
    Processador NLP completo para documentos jur√≠dicos brasileiros
    Aplica an√°lise cognitiva e estrutura√ß√£o para sistemas RAG
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Inicializa o processador NLP

        Args:
            config: Configura√ß√µes personalizadas
        """
        self.config = config or {}

        # Componentes NLP
        self.entity_extractor = LegalEntityExtractor()
        self.summarizer = LegalSummarizer()
        self.rag_indexer = RAGIndexer()

        # Configura√ß√µes
        self.enable_ner = self.config.get('enable_ner', True)
        self.enable_summarization = self.config.get('enable_summarization', True)
        self.enable_embeddings = self.config.get('enable_embeddings', False)

        print("\n" + "=" * 60)
        print("  üß† PROCESSADOR NLP JUR√çDICO INICIALIZADO")
        print("  Metodologia: Estrategista Jur√≠dico-Cognitivo")
        print("=" * 60)
        print(f"  ‚úì Extra√ß√£o de Entidades (NER): {'Ativo' if self.enable_ner else 'Desativado'}")
        print(f"  ‚úì Sumariza√ß√£o: {'Ativo' if self.enable_summarization else 'Desativado'}")
        print(f"  ‚úì Embeddings para RAG: {'Ativo' if self.enable_embeddings else 'Desativado'}")
        print("=" * 60 + "\n")

    def process_document(self, document: Dict[str, Any], doc_index: int) -> Dict[str, Any]:
        """
        Processa um √∫nico documento com an√°lise NLP completa

        Args:
            document: Documento com conte√∫do extra√≠do
            doc_index: √çndice do documento

        Returns:
            Documento enriquecido com an√°lise NLP
        """
        content = document.get('content', '')
        doc_id = document.get('id', f'doc_{doc_index}')

        print(f"  [{doc_index}] Processando NLP: {document.get('filename', 'N/A')}")

        # Inicializa estrutura de an√°lise NLP
        nlp_analysis = {
            'entidades': {},
            'sumarizacao': {},
            'analise_estrutural': {},
            'classificacao': {},
            'metricas': {}
        }

        try:
            # 1. Extra√ß√£o de Entidades Nomeadas (NER)
            if self.enable_ner and len(content) > 50:
                print(f"      ‚Üí Extraindo entidades jur√≠dicas...")
                entities_data = extract_legal_entities(content)

                nlp_analysis['entidades'] = entities_data['entidades']
                nlp_analysis['analise_estrutural'] = entities_data['analise_estrutural']
                nlp_analysis['metricas']['total_entidades'] = entities_data['estatisticas']['total_entidades']

            # 2. Sumariza√ß√£o
            if self.enable_summarization and len(content.split()) > 100:
                print(f"      ‚Üí Gerando sumariza√ß√£o...")
                summary_data = summarize_legal_text(content, max_length=500)

                nlp_analysis['sumarizacao'] = {
                    'resumo': summary_data['summary'],
                    'metodo': summary_data['method'],
                    'pontos_chave': summary_data['key_points'],
                    'secoes': summary_data['sections'],
                    'taxa_compressao': summary_data['compression_ratio']
                }

            # 3. Classifica√ß√£o de Documento
            print(f"      ‚Üí Classificando documento...")
            classification = self._classify_document(content)
            nlp_analysis['classificacao'] = classification

            # 4. An√°lise de Sentimento/Decis√£o
            decision_analysis = self._analyze_decision(content)
            nlp_analysis['analise_decisao'] = decision_analysis

            # 5. M√©tricas de complexidade
            complexity = self._calculate_complexity(content)
            nlp_analysis['metricas']['complexidade'] = complexity

            print(f"      ‚úì NLP conclu√≠do")

        except Exception as e:
            print(f"      ‚ö† Erro no processamento NLP: {str(e)}")
            nlp_analysis['erro'] = str(e)

        # Adiciona an√°lise NLP ao documento
        document['nlp_analysis'] = nlp_analysis

        return document

    def _classify_document(self, content: str) -> Dict[str, Any]:
        """
        Classifica o tipo e natureza do documento jur√≠dico

        Args:
            content: Conte√∫do do documento

        Returns:
            Classifica√ß√£o do documento
        """
        classification = {
            'tipo_documento': 'desconhecido',
            'natureza': [],
            'area_direito': [],
            'confianca': 0.0
        }

        content_lower = content.lower()

        # Tipos de documento
        doc_types = {
            'acordao': ['ac√≥rd√£o', 'acord√£o', 'voto', 'relator'],
            'sentenca': ['senten√ßa', 'julgo procedente', 'julgo improcedente'],
            'peticao': ['peti√ß√£o', 'requer', 'excelent√≠ssimo'],
            'parecer': ['parecer', 'opina', 'manifesta-se'],
            'decisao': ['decis√£o', 'defiro', 'indefiro'],
            'despacho': ['despacho', 'vista', 'manifeste-se']
        }

        for doc_type, keywords in doc_types.items():
            if any(kw in content_lower for kw in keywords):
                classification['tipo_documento'] = doc_type
                break

        # √Åreas do direito
        areas = {
            'civil': ['direito civil', 'obriga√ß√£o', 'contrato', 'responsabilidade civil'],
            'penal': ['direito penal', 'crime', 'pena', 'c√≥digo penal', 'condena√ß√£o'],
            'trabalhista': ['trabalhista', 'clt', 'empregado', 'empregador', 'rescis√£o'],
            'tributario': ['tribut√°rio', 'imposto', 'tributo', 'icms', 'irpf'],
            'constitucional': ['constitucional', 'constitui√ß√£o', 'stf', 'adi', 'adpf'],
            'administrativo': ['administrativo', 'servidor p√∫blico', 'licita√ß√£o']
        }

        for area, keywords in areas.items():
            if any(kw in content_lower for kw in keywords):
                classification['area_direito'].append(area)

        return classification

    def _analyze_decision(self, content: str) -> Dict[str, Any]:
        """
        Analisa a decis√£o judicial (se aplic√°vel)

        Args:
            content: Conte√∫do do documento

        Returns:
            An√°lise da decis√£o
        """
        decision = {
            'tipo': 'nao_aplicavel',
            'resultado': None,
            'fundamentacao_principal': []
        }

        content_lower = content.lower()

        # Detecta tipo de decis√£o
        if any(term in content_lower for term in ['julgo procedente', 'dou provimento', 'acordam em dar provimento']):
            decision['tipo'] = 'procedente'
            decision['resultado'] = 'favoravel_autor'

        elif any(term in content_lower for term in ['julgo improcedente', 'nego provimento', 'acordam em negar']):
            decision['tipo'] = 'improcedente'
            decision['resultado'] = 'favoravel_reu'

        elif 'parcialmente procedente' in content_lower:
            decision['tipo'] = 'parcialmente_procedente'
            decision['resultado'] = 'parcial'

        return decision

    def _calculate_complexity(self, content: str) -> Dict[str, Any]:
        """
        Calcula m√©tricas de complexidade do texto jur√≠dico

        Args:
            content: Conte√∫do do documento

        Returns:
            M√©tricas de complexidade
        """
        words = content.split()
        sentences = content.split('.')

        complexity = {
            'total_palavras': len(words),
            'total_sentencas': len(sentences),
            'media_palavras_sentenca': len(words) / max(len(sentences), 1),
            'palavras_complexas': 0,
            'nivel': 'simples'
        }

        # Conta palavras complexas (> 10 caracteres)
        complexity['palavras_complexas'] = sum(1 for w in words if len(w) > 10)

        # Define n√≠vel de complexidade
        avg_words = complexity['media_palavras_sentenca']
        if avg_words > 30:
            complexity['nivel'] = 'muito_complexo'
        elif avg_words > 20:
            complexity['nivel'] = 'complexo'
        elif avg_words > 15:
            complexity['nivel'] = 'medio'

        return complexity

    def process_batch(self, documents: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Processa um lote de documentos

        Args:
            documents: Lista de documentos

        Returns:
            Lista de documentos processados
        """
        print(f"\nüîÑ Iniciando processamento NLP de {len(documents)} documentos...")

        processed_docs = []

        for idx, doc in enumerate(documents, 1):
            processed_doc = self.process_document(doc, idx)
            processed_docs.append(processed_doc)

        print(f"‚úì Processamento NLP conclu√≠do para {len(processed_docs)} documentos\n")

        return processed_docs

    def create_rag_index(
        self,
        documents: List[Dict[str, Any]],
        chunk_size: int = 512,
        overlap: int = 50
    ) -> Dict[str, Any]:
        """
        Cria √≠ndice RAG a partir dos documentos processados

        Args:
            documents: Documentos processados
            chunk_size: Tamanho dos chunks
            overlap: Sobreposi√ß√£o

        Returns:
            Dataset RAG indexado
        """
        print("\nüîÑ Criando √≠ndice RAG...")

        rag_dataset = self.rag_indexer.prepare_rag_dataset(
            documents,
            chunk_size=chunk_size,
            overlap=overlap,
            create_embeddings=self.enable_embeddings
        )

        print("‚úì √çndice RAG criado com sucesso\n")

        return rag_dataset


def process_legal_documents(
    documents: List[Dict[str, Any]],
    config: Optional[Dict[str, Any]] = None
) -> List[Dict[str, Any]]:
    """
    Fun√ß√£o helper para processar documentos jur√≠dicos

    Args:
        documents: Lista de documentos
        config: Configura√ß√µes

    Returns:
        Documentos processados com an√°lise NLP
    """
    processor = LegalNLPProcessor(config)
    return processor.process_batch(documents)
